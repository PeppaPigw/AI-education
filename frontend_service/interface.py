import io
import os
import random
import sys
from contextlib import redirect_stdout
import shutil
import logging
import re
import json
import gradio as gr
from dotenv import load_dotenv
import plotly.graph_objects as go
import base64 

try:
    sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
    from AgentModule import create_agent
    from AgentModule.edu_agent import run_agent
    from LearningPlanModule import LearningPlan
    from QuizModule import generate_learning_plan_from_quiz, prepare_quiz_questions
    from SummaryModule import StudySummaryGenerator
    from tools.language_handler import LanguageHandler
    from tools.rag_service import get_rag_service
    
    # åŠ è½½ç¯å¢ƒå˜é‡
    dotenv_path = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".env"))
    load_dotenv(dotenv_path)
    # æ£€æŸ¥ API Key
    if not os.environ.get("api_key"):
        raise RuntimeError("api_key is not set. Create a .env file or export the variable.")
    # åˆå§‹åŒ–æœåŠ¡
    agent = create_agent()
    rag_service = get_rag_service()
    retriever = rag_service.get_retriever()
except (ImportError, RuntimeError, FileNotFoundError) as e:
    print(f"âš ï¸  Warning: Could not import all external modules: {e}. Running in standalone mode.")
    print("AI-related functionalities (chat, quiz, etc.) will be disabled.")
    # åˆ›å»ºä¼ªå¯¹è±¡ä»¥é¿å…ç¨‹åºå´©æºƒ
    agent = None
    retriever = None
    # ä¸º LanguageHandler åˆ›å»ºä¸€ä¸ªç®€å•çš„æ›¿ä»£å“
    class LanguageHandler:
        @staticmethod
        def dropdown_choices(): return ["Auto-detect", "English", "Polish", "Chinese"]
        @staticmethod
        def code_from_display(display): return "auto" if display == "Auto-detect" else display[:2].lower()
        @staticmethod
        def choose_or_detect(text, lang_code="en"): return lang_code
        @staticmethod
        def ensure_language(text, lang_code): return text

logger = logging.getLogger(__name__)
# CSS æ ·å¼ (æœªä½œä¿®æ”¹)
CSS = """
* { font-family: 'Segoe UI', Tahoma, sans-serif; }
#chatbot .message.user { background-color: #e6f3ff; border-radius: 8px; }
#chatbot .message.bot { background-color: #f0f0f0; border-radius: 8px; }
#chatbot .message.bot.fallback { background-color: #fff9c4; }
.gradio-container { max-width: none !important; }
.full-height-plot, .full-height-plot > div {
    height: 100vh !important;
    min-height: 80vh;
}
.full-height-pdf, .full-height-pdf > div {
    height: 100vh !important;
}
/* ç¡®ä¿ iframe å æ»¡å®¹å™¨ */
#pdf-viewer-container, #pdf-viewer-container iframe {
    height: 98vh !important;
    width: 100%;
}
"""
# --- åŸå§‹åç«¯å‡½æ•° (æœªä½œä¿®æ”¹) ---
def respond(
    message: str,
    history: list[dict],
    lang_choice: str,
    retriever=None,
) -> tuple[list[dict], str]:
    """Return updated chat history and logs."""
    if not agent:
        history.append({"role": "user", "content": message})
        history.append({"role": "assistant", "content": "Chatbot is disabled (module not loaded)."})
        yield history, "Chatbot is disabled."
        return
    history = history + [
        {"role": "user", "content": message},
        {"role": "assistant", "content": "..."},
    ]
    yield history, ""
    code = LanguageHandler.code_from_display(lang_choice)
    language = code if code != "auto" else LanguageHandler.choose_or_detect(message)
    buffer = io.StringIO()
    with redirect_stdout(buffer):
        result, used_fallback, used_retriever = run_agent(
            message, executor=agent, retriever=retriever, return_details=True
        )
        result = LanguageHandler.ensure_language(result, language)
        if used_fallback:
            notice = LanguageHandler.ensure_language(
                # "LLMç”Ÿæˆçš„æ¶ˆæ¯ï¼Œæ£€æŸ¥å…¶æ­£ç¡®æ€§Â·",
                language,
            )
            result = f"<div class='fallback'>{notice}<br>{result}</div>"
        elif used_retriever:
            notice = LanguageHandler.ensure_language(
                language,
            )
            result = f"<div class='retrieval'>{notice}<br>{result}</div>"
    history[-1] = {"role": "assistant", "content": result}
    logs = buffer.getvalue()
    yield history, logs

def respond_with_retriever(message: str, history: list[dict], lang_choice: str):
    yield from respond(message, history, lang_choice, retriever)

def process_knowledge(files: list):
    """åŸå§‹å‡½æ•°ï¼šä»…å¤„ç†æ–‡ä»¶å¹¶å­˜å…¥ RAG service"""
    if not files:
        yield "âš ï¸ No files uploaded."
        return
    yield "â³ Processing for RAG..."
    yield f"âœ… Processed {len(files)} file(s) for RAG."

def _format_question(q: dict) -> str:
    """Return formatted question text with options on separate lines."""
    text = q["question"]
    text = re.sub(r"\s*([abcd]\))", r"\n\1", text, flags=re.I)
    text = text.strip()
    return f"**{q['topic']}**\n\n{text}"

def start_quiz(subject: str, lang_choice: str, retriever=None):
    """Generate quiz questions and return the first one with state."""
    if not agent:
        return "Quiz is disabled.", {}, "Quiz is disabled."
    code = LanguageHandler.code_from_display(lang_choice)
    language = code if code != "auto" else LanguageHandler.choose_or_detect(subject)
    questions, used_retriever = prepare_quiz_questions(
        subject, language=language, retriever=retriever
    )
    if not questions:
        return "Failed to generate quiz.", {}, ""
    state = {
        "subject": subject,
        "language": language,
        "questions": questions,
        "index": 0,
        "scores": {},
        "correct_total": 0,
    }
    first_q = _format_question(questions[0])
    notice = (
        "ğŸ“„ Quiz ä½¿ç”¨æ–‡æ¡£ä¸Šä¸‹æ–‡ç”Ÿæˆ"
    )
    return first_q, state, notice

def answer_quiz(choice: str, state: dict) -> tuple[str, dict, str]:
    """Process an answer button click and return next question or results."""
    if not state or state.get("index") is None:
        return "Quiz not started.", state, ""
    idx = state["index"]
    questions = state["questions"]
    if idx >= len(questions):
        return "", state, _compile_results(state)
    current = questions[idx]
    topic = current["topic"]
    correct = current["correct"]
    scores = state.setdefault("scores", {}).setdefault(topic, [0, 0])
    scores[1] += 1
    if choice.lower() == correct or correct == "?":
        scores[0] += 1
        state["correct_total"] += 1
    state["index"] += 1
    if state["index"] >= len(questions):
        return "", state, _compile_results(state)
    next_q = _format_question(questions[state["index"]])
    return next_q, state, ""

def _compile_results(state: dict) -> str:
    lines = []
    total_questions = 0
    total_correct = state.get("correct_total", 0)
    for topic, (corr, tot) in state.get("scores", {}).items():
        perc = (corr / tot) * 100 if tot else 0
        lines.append(f"{topic}: {corr}/{tot} ({perc:.2f}%)")
        total_questions += tot
    if lines:
        overall = sum(
            (corr / tot) * 100 if tot else 0 for corr, tot in state["scores"].values()
        )
        overall /= len(state["scores"])
        lines.append(
            f"\nOverall Score: {total_correct}/{total_questions} ({overall:.2f}%)"
        )
    result = "\n".join(lines)
    lang = state.get("language", "auto")
    return LanguageHandler.ensure_language(result, lang)

def run_learning_plan_interface(name: str, goals: str, lang_choice: str) -> str:
    if not agent: return "Learning plan is disabled."
    code = LanguageHandler.code_from_display(lang_choice)
    language = code if code != "auto" else LanguageHandler.choose_or_detect(goals)
    plan = LearningPlan(user_name=name, user_language=language)
    goals_list = [g.strip() for g in goals.split(";") if g.strip()]
    user_input = {"goals": goals_list}
    buffer = io.StringIO()
    with redirect_stdout(buffer):
        plan.generate_plan_from_prompt(user_input)
        plan.display_plan()
        plan.save_to_file()
    return buffer.getvalue()

def run_learning_plan_from_quiz(name: str, state: dict, lang_choice: str) -> str:
    if not agent: return "Learning plan is disabled."
    if not state or not state.get("scores"):
        return "No quiz results available."
    code = LanguageHandler.code_from_display(lang_choice)
    language = (
        code
        if code != "auto"
        else state.get("language") or LanguageHandler.choose_or_detect(name)
    )
    buffer = io.StringIO()
    with redirect_stdout(buffer):
        generate_learning_plan_from_quiz(name, state["scores"], language)
    return buffer.getvalue()

def run_summary_interface(topic: str, lang_choice: str, retriever=None) -> str:
    if not agent: return "Summary is disabled."
    code = LanguageHandler.code_from_display(lang_choice)
    language = code if code != "auto" else LanguageHandler.choose_or_detect(topic)
    summarizer = StudySummaryGenerator(retriever=retriever)
    summary, used_retriever = summarizer.generate_summary(
        topic, language=language, retriever=retriever
    )
    notice = (
        "ğŸ“„ Summary ä½¿ç”¨æ–‡æ¡£ä¸Šä¸‹æ–‡ç”Ÿæˆ"
    )
    return f"{notice}\n\n{summary}"

KNOWLEDGE_JSON_PATH = "data/course/big_data.json"
def load_knowledge_data(json_path: str) -> dict:
    """ä»JSONæ–‡ä»¶åŠ è½½çŸ¥è¯†å›¾è°±æ•°æ®"""
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        return {}
        

def get_all_learning_nodes(graph_data: dict) -> list:
    """ä»çŸ¥è¯†æ•°æ®ä¸­æå–æ‰€æœ‰å¯å­¦ä¹ çš„èŠ‚ç‚¹ï¼ˆgrandchildrenå’Œgreat-grandchildrenï¼‰"""
    learning_nodes = []
    for child in graph_data.get("children", []):
        for grandchild in child.get("grandchildren", []):
            # æ·»åŠ grandchildrenèŠ‚ç‚¹
            gc_name = grandchild.get("name")
            gc_resources = grandchild.get("resource_path", [])
            # if gc_resources and isinstance(gc_resources, list) and len(gc_resources) > 0:
            learning_nodes.append(gc_name)
            
            # æ·»åŠ great-grandchildrenèŠ‚ç‚¹
            for great_grandchild in grandchild.get("great-grandchildren", []):
                ggc_name = great_grandchild.get("name")
                ggc_resources = great_grandchild.get("resource_path", [])
                # if ggc_resources and isinstance(ggc_resources, list) and len(ggc_resources) > 0:
                learning_nodes.append(ggc_name)
    
    return learning_nodes

def create_knowledge_graph_figure(graph_data: dict):
    """ä½¿ç”¨Plotlyåˆ›å»º4å±‚çŸ¥è¯†å›¾è°±çš„å¯è§†åŒ–Figure"""
    if not graph_data:
        return go.Figure()
    
    fig = go.Figure()
    nodes = {'labels': [], 'colors': [], 'x': [], 'y': []}
    edges = {'x': [], 'y': []}
    
    # RootèŠ‚ç‚¹ï¼ˆç¬¬0å±‚ï¼‰
    root_name = graph_data.get("root_name", "Root")
    nodes['labels'].append(root_name)
    nodes['colors'].append("#FFA07A")  # çŠç‘šè‰²
    nodes['x'].append(0); nodes['y'].append(0)
    
    y_pos_child = 0
    
    for child in graph_data.get("children", []):
        child_name = child.get("name")
        child_color = "#87CEFA" if child.get("flag") == "1" else "#D3D3D3"
        
        # ChildrenèŠ‚ç‚¹ï¼ˆç¬¬1å±‚ï¼‰
        nodes['labels'].append(child_name)
        nodes['colors'].append(child_color)
        nodes['x'].append(1)
        nodes['y'].append(y_pos_child)
        
        # Rootåˆ°Childçš„è¿çº¿
        edges['x'].extend([0, 1, None])
        edges['y'].extend([0, y_pos_child, None])
        
        y_pos_grandchild = y_pos_child
        
        for grandchild in child.get("grandchildren", []):
            grandchild_name = grandchild.get("name")
            grandchild_color = "#90EE90" if grandchild.get("flag") == "1" else "#D3D3D3"
            
            # GrandchildrenèŠ‚ç‚¹ï¼ˆç¬¬2å±‚ï¼‰
            nodes['labels'].append(grandchild_name)
            nodes['colors'].append(grandchild_color)
            nodes['x'].append(2)
            nodes['y'].append(y_pos_grandchild)
            
            # Childåˆ°Grandchildçš„è¿çº¿
            edges['x'].extend([1, 2, None])
            edges['y'].extend([y_pos_child, y_pos_grandchild, None])
            
            y_pos_great_grandchild = y_pos_grandchild
            
            # Great-grandchildrenèŠ‚ç‚¹ï¼ˆç¬¬3å±‚ï¼‰
            for great_grandchild in grandchild.get("great-grandchildren", []):
                ggc_name = great_grandchild.get("name")
                ggc_color = "#FFD700" if great_grandchild.get("flag") == "1" else "#D3D3D3"  # é‡‘è‰²
                
                nodes['labels'].append(ggc_name)
                nodes['colors'].append(ggc_color)
                nodes['x'].append(3)
                nodes['y'].append(y_pos_great_grandchild)
                
                # Grandchildåˆ°Great-grandchildçš„è¿çº¿
                edges['x'].extend([2, 3, None])
                edges['y'].extend([y_pos_grandchild, y_pos_great_grandchild, None])
                
                y_pos_great_grandchild += 0.8
            
            y_pos_grandchild += max(1.5, len(grandchild.get("great-grandchildren", [])) * 0.8)
        
        y_pos_child += max(2, y_pos_grandchild - y_pos_child + 1)
    
    # æ·»åŠ è¿çº¿
    fig.add_trace(go.Scatter(
        x=edges['x'], y=edges['y'],
        mode='lines',
        line=dict(width=1, color='#888'),
        hoverinfo='none'
    ))
    
    # æ·»åŠ èŠ‚ç‚¹
    fig.add_trace(go.Scatter(
        x=nodes['x'], y=nodes['y'],
        mode='markers+text',
        text=nodes['labels'],
        textposition="bottom center",
        hoverinfo='text',
        marker=dict(
            symbol='circle',
            size=25,
            color=nodes['colors'],
            line=dict(width=2, color='#555')
        )
    ))
    
    fig.update_layout(
        showlegend=False,
        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        plot_bgcolor='white',
        margin=dict(l=10, r=10, t=30, b=10)
    )
    
    return fig

def find_resources_for_node(node_name: str, graph_data: dict) -> list:
    """åœ¨4å±‚ç»“æ„ä¸­æŸ¥æ‰¾æŒ‡å®šèŠ‚ç‚¹çš„èµ„æº"""
    for child in graph_data.get("children", []):
        for grandchild in child.get("grandchildren", []):
            # æ£€æŸ¥grandchildrenå±‚çº§
            if grandchild.get("name") == node_name:
                resources = grandchild.get("resource_path", [])
                return resources if isinstance(resources, list) else []
            
            # æ£€æŸ¥great-grandchildrenå±‚çº§
            for great_grandchild in grandchild.get("great-grandchildren", []):
                if great_grandchild.get("name") == node_name:
                    resources = great_grandchild.get("resource_path", [])
                    return resources if isinstance(resources, list) else []
    
    return []

def upload_and_update_resource(files: list, selected_node: str, current_data: dict):
    """ä¸Šä¼ æ–‡ä»¶ï¼Œä¿å­˜ï¼Œå¹¶æ›´æ–°JSONæ–‡ä»¶ï¼ˆæ”¯æŒ4å±‚ç»“æ„ï¼‰"""
    if not files:
        return "âš ï¸ æœªé€‰æ‹©æ–‡ä»¶ã€‚", current_data, gr.update()
    if not selected_node:
        return "âŒ é”™è¯¯ï¼šæ²¡æœ‰é€‰å®šçš„å­¦ä¹ èŠ‚ç‚¹æ¥å…³è”æ–‡ä»¶ã€‚", current_data, gr.update()
    
    save_dir = os.path.join("data", "RAG_files")
    os.makedirs(save_dir, exist_ok=True)
    
    newly_added_paths = []
    for file in files:
        filename = os.path.basename(file.name)
        dest_path = os.path.join(save_dir, filename)
        shutil.copy2(file.name, dest_path)
        logger.info(f"Saved {file.name} to {dest_path}")
        newly_added_paths.append(dest_path)
    
    updated = False
    new_choices = []
    
    # åœ¨4å±‚ç»“æ„ä¸­æŸ¥æ‰¾å¹¶æ›´æ–°èŠ‚ç‚¹
    for child in current_data.get("children", []):
        for grandchild in child.get("grandchildren", []):
            # æ£€æŸ¥grandchildrenå±‚çº§
            if grandchild.get("name") == selected_node:
                if "resource_path" not in grandchild or not grandchild["resource_path"]:
                    grandchild["resource_path"] = []
                grandchild["resource_path"].extend(newly_added_paths)
                new_choices = grandchild.get("resource_path", [])
                updated = True
                break
            
            # æ£€æŸ¥great-grandchildrenå±‚çº§
            for great_grandchild in grandchild.get("great-grandchildren", []):
                if great_grandchild.get("name") == selected_node:
                    if "resource_path" not in great_grandchild or not great_grandchild["resource_path"]:
                        great_grandchild["resource_path"] = []
                    great_grandchild["resource_path"].extend(newly_added_paths)
                    new_choices = great_grandchild.get("resource_path", [])
                    updated = True
                    break
            
            if updated:
                break
        if updated:
            break
    
    if updated:
        with open(KNOWLEDGE_JSON_PATH, 'w', encoding='utf-8') as f:
            json.dump(current_data, f, indent=2, ensure_ascii=False)
        msg = f"âœ… æˆåŠŸä¸Šä¼  {len(files)} ä¸ªæ–‡ä»¶å¹¶å…³è”åˆ° '{selected_node}'."
        return msg, current_data, gr.update(choices=new_choices, value=new_choices[0] if new_choices else None)
    else:
        msg = f"âŒ æœªèƒ½åœ¨JSONä¸­æ‰¾åˆ°èŠ‚ç‚¹ '{selected_node}'ã€‚"
        return msg, current_data, gr.update()
# <--- ä¿®æ”¹ç‚¹ 2: æ·»åŠ æ–°çš„è¾…åŠ©å‡½æ•°æ¥ç”Ÿæˆ PDF çš„ iframe ---
def show_pdf_in_iframe(pdf_path: str):
    """
    è¯»å–PDFæ–‡ä»¶ï¼Œç¼–ç ä¸ºBase64ï¼Œå¹¶è¿”å›ä¸€ä¸ªHTML iframeå­—ç¬¦ä¸²ã€‚
    å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ™è¿”å›é”™è¯¯æ¶ˆæ¯ã€‚
    """
    if not pdf_path or not os.path.exists(pdf_path):
        return "<div style='text-align: center; padding: 20px;'>âŒ PDF æ–‡ä»¶æœªæ‰¾åˆ°æˆ–è·¯å¾„æ— æ•ˆã€‚</div>"
    
    try:
        with open(pdf_path, "rb") as f:
            pdf_bytes = f.read()
        
        pdf_base64 = base64.b64encode(pdf_bytes).decode("utf-8")
        
        html = f'''
        <iframe
            src="data:application/pdf;base64,{pdf_base64}"
            width="100%"
            height="100%"
            type="application/pdf">
        </iframe>
        '''
        return html
    except Exception as e:
        logger.error(f"Error reading PDF {pdf_path}: {e}")
        return f"<div style='text-align: center; padding: 20px;'>âŒ è¯»å– PDF æ—¶å‡ºé”™: {e}</div>"
def build_interface() -> gr.Blocks:
    """åˆ›å»ºç¬¦åˆæ–°å¸ƒå±€è¦æ±‚çš„ Gradio UI"""
    initial_data = load_knowledge_data(KNOWLEDGE_JSON_PATH)
    
    with gr.Blocks(css=CSS, theme=gr.themes.Soft()) as demo:
        # --- çŠ¶æ€ç®¡ç† ---
        knowledge_data_state = gr.State(initial_data)
        selected_grandchild_state = gr.State()
        with gr.Row():
            # --- å·¦ä¾§ 3/4 ä¸»æ˜¾ç¤ºåŒº ---
            with gr.Column(scale=3):
                knowledge_graph_plot = gr.Plot(label="çŸ¥è¯†å›¾è°±", value=create_knowledge_graph_figure(initial_data),elem_classes=["full-height-plot"])
                # <--- ä¿®æ”¹ç‚¹ 3.1: å°† gr.File æ›¿æ¢ä¸º gr.HTML ---
                pdf_viewer_html = gr.HTML(visible=False, elem_id="pdf-viewer-container")
            # --- å³ä¾§ 1/4 åŠŸèƒ½/èµ„æºåŒº ---
            with gr.Column(scale=1):
                gr.Markdown("<h1>AI-Education ğŸ“</h1>")
                # MODIFIED: New interaction flow starts with this dropdown
                with gr.Group(visible=True) as node_selection_group:
                    learning_nodes_list = get_all_learning_nodes(initial_data)
                
                    node_selector = gr.Dropdown(choices=learning_nodes_list , label="é€‰æ‹©ä¸€ä¸ªçŸ¥è¯†èŠ‚ç‚¹å¼€å§‹å­¦ä¹ ")
                # çŠ¶æ€2: æ˜¾ç¤ºé€‰ä¸­èŠ‚ç‚¹çš„èµ„æº
                with gr.Group(visible=False) as resource_display_group:
                    gr.Markdown("### ğŸ“š å­¦ä¹ èµ„æº")
                    resource_selector = gr.Radio(label="é€‰æ‹©ä¸€ä¸ªPDFè¿›è¡Œé˜…è¯»", choices=[])
                
                # çŠ¶æ€3: PDFé˜…è¯»æ—¶ï¼Œæ˜¾ç¤ºåŠŸèƒ½é¢æ¿
                with gr.Group(visible=False) as main_function_group:
                    lang_select = gr.Dropdown(choices=LanguageHandler.dropdown_choices(), value=LanguageHandler.dropdown_choices()[0], label="è¯­è¨€é€‰æ‹©")
                    feature_choices = ["ğŸ¤– AI åŠ©æ•™", "ğŸ“ éšå ‚æµ‹éªŒ", "ğŸ—ºï¸ å­¦ä¹ è®¡åˆ’", "ğŸ“œ çŸ¥è¯†æ€»ç»“", "ğŸ“¤ ä¸Šä¼ æ–°èµ„æº"]
                    feature_select = gr.Dropdown(choices=feature_choices, value=feature_choices[0], label="åŠŸèƒ½é€‰æ‹©")
                    
                    with gr.Group(visible=True) as chat_group:
                        chatbot = gr.Chatbot(elem_id="chatbot", label="Chat", height=500)
                        with gr.Row():
                            msg = gr.Textbox(placeholder="è¾“å…¥ä½ çš„é—®é¢˜...", container=False, scale=4)
                            send = gr.Button("å‘é€", variant="primary", scale=1)
                        # with gr.Accordion("ç»ˆç«¯è¾“å‡º", open=False):
                        logs = gr.Textbox(label=None, lines=2)
                        clear = gr.Button("æ¸…é™¤å¯¹è¯å†å²")
                    
                    with gr.Group(visible=False) as quiz_group:
                        
                        quiz_subject = gr.Textbox(label="æµ‹éªŒä¸»é¢˜")
                        start_btn = gr.Button("å¼€å§‹æµ‹éªŒ", variant="primary")
                        quiz_question = gr.Markdown(label="é—®é¢˜")
                        with gr.Row():
                            btn_a = gr.Button("A"); btn_b = gr.Button("B"); btn_c = gr.Button("C"); btn_d = gr.Button("D")
                        quiz_result = gr.Markdown(label="ç»“æœ")
                        quiz_state = gr.State()
                        gr.Markdown("---")
                        quiz_name = gr.Textbox(label="ä½ çš„åå­— (ç”¨äºç”Ÿæˆå­¦ä¹ è®¡åˆ’)")
                        plan_quiz_btn = gr.Button("æ ¹æ®æµ‹éªŒç»“æœç”Ÿæˆå­¦ä¹ è®¡åˆ’")
                        plan_quiz_output = gr.Textbox(label="è®¡åˆ’è¾“å‡º", lines=10, interactive=False)
                    with gr.Group(visible=False) as plan_group:
                        
                        plan_name = gr.Textbox(label="ä½ çš„åå­—")
                        plan_goals = gr.Textbox(label="å­¦ä¹ ç›®æ ‡ (ç”¨åˆ†å·éš”å¼€)")
                        plan_btn = gr.Button("ç”Ÿæˆè®¡åˆ’", variant="primary")
                        plan_output = gr.Textbox(label="è®¡åˆ’è¾“å‡º", lines=10, interactive=False)
                    
                    with gr.Group(visible=False) as summary_group:
                        
                        sum_topic = gr.Textbox(label="ä¸»é¢˜æˆ–ææ–™")
                        sum_btn = gr.Button("ç”Ÿæˆæ€»ç»“", variant="primary")
                        sum_output = gr.Textbox(label="æ€»ç»“å†…å®¹", lines=10, interactive=False)
                    
                    with gr.Group(visible=False) as upload_group:
                        
                        gr.Markdown("ä¸Šä¼ æ–‡ä»¶åˆ°å½“å‰å­¦ä¹ èŠ‚ç‚¹ï¼š")
                        current_node_display = gr.Markdown()
                        upload_files_new = gr.File(file_count="multiple", label="é€‰æ‹©PDFæ–‡ä»¶")
                        upload_btn_new = gr.Button("ä¸Šä¼ å¹¶å…³è”", variant="primary")
                        upload_status_new = gr.Markdown()
        
        # --- UI äº‹ä»¶å¤„ç†ä¸é€»è¾‘æµ ---
        # MODIFIED: New function to handle node selection from dropdown
        def on_node_select(selected_node_name: str, graph_data: dict):
            if not selected_node_name:
                return gr.update(visible=False), None, gr.update(), gr.update(visible=False), gr.update(visible=True)
            
            resources = find_resources_for_node(selected_node_name, graph_data)
            
            return (
                gr.update(visible=True),
                selected_node_name,
                gr.update(choices=resources, value=None),
                gr.update(visible=False),
                gr.update(visible=True)
            )
        # MODIFIED: Event handler is now on the dropdown
        node_selector.change(
            fn=on_node_select,
            inputs=[node_selector, knowledge_data_state],
            outputs=[resource_display_group, selected_grandchild_state, resource_selector, main_function_group, knowledge_graph_plot]
        )
        
        # <--- ä¿®æ”¹ç‚¹ 3.2: ä¿®æ”¹ on_pdf_select å‡½æ•°ä»¥è¾“å‡º HTML ---
        def on_pdf_select(selected_pdf: str, selected_grandchild: str):
            if not selected_pdf:
                # å¦‚æœæ²¡æœ‰é€‰æ‹©PDFï¼Œåˆ™ä¸åšä»»ä½•äº‹æƒ…
                return gr.update(), gr.update(), gr.update(), gr.update(), gr.update(), gr.update()
            
            # è°ƒç”¨æ–°å‡½æ•°ç”Ÿæˆ iframe HTML
            pdf_html_content = show_pdf_in_iframe(selected_pdf)
            
            return (
                gr.update(visible=False), # éšè—çŸ¥è¯†å›¾è°±
                gr.update(visible=True, value=pdf_html_content), # æ˜¾ç¤ºHTMLç»„ä»¶å¹¶åŠ è½½iframeå†…å®¹
                gr.update(visible=False), # éšè—èŠ‚ç‚¹é€‰æ‹©å™¨
                gr.update(visible=False), # éšè—èµ„æºé€‰æ‹©é¢æ¿
                gr.update(visible=True),  # æ˜¾ç¤ºä¸»åŠŸèƒ½é¢æ¿
                f"**å½“å‰èŠ‚ç‚¹**: {selected_grandchild}" # åœ¨ä¸Šä¼ æ¨¡å—ä¸­æ˜¾ç¤ºå½“å‰èŠ‚ç‚¹
            )
        
        # <--- ä¿®æ”¹ç‚¹ 3.3: æ›´æ–° change äº‹ä»¶çš„ outputs ---
        resource_selector.change(
            fn=on_pdf_select,
            inputs=[resource_selector, selected_grandchild_state],
            outputs=[knowledge_graph_plot, pdf_viewer_html, node_selection_group, resource_display_group, main_function_group, current_node_display]
        )
        
        def switch_feature_visibility(feature_name: str):
            visibility = {choice: (feature_name == choice) for choice in feature_choices}
            return {
                chat_group: gr.update(visible=visibility[feature_choices[0]]),
                quiz_group: gr.update(visible=visibility[feature_choices[1]]),
                plan_group: gr.update(visible=visibility[feature_choices[2]]),
                summary_group: gr.update(visible=visibility[feature_choices[3]]),
                upload_group: gr.update(visible=visibility[feature_choices[4]]),
            }
        feature_select.change(
            fn=switch_feature_visibility,
            inputs=feature_select,
            outputs=[chat_group, quiz_group, plan_group, summary_group, upload_group],
            queue=False
        )
        # Backend function bindings (unchanged)
        def clear_history(): return [], "", ""
        msg.submit(respond_with_retriever, [msg, chatbot, lang_select], [chatbot, logs]).then(lambda: "", outputs=msg)
        send.click(respond_with_retriever, [msg, chatbot, lang_select], [chatbot, logs]).then(lambda: "", outputs=msg)
        clear.click(clear_history, None, [chatbot, logs, msg])
        
        start_btn.click(lambda sub, lang: start_quiz(sub, lang, retriever), [quiz_subject, lang_select], [quiz_question, quiz_state, quiz_result])
        btn_a.click(lambda st: answer_quiz("a", st), quiz_state, [quiz_question, quiz_state, quiz_result])
        btn_b.click(lambda st: answer_quiz("b", st), quiz_state, [quiz_question, quiz_state, quiz_result])
        btn_c.click(lambda st: answer_quiz("c", st), quiz_state, [quiz_question, quiz_state, quiz_result])
        btn_d.click(lambda st: answer_quiz("d", st), quiz_state, [quiz_question, quiz_state, quiz_result])
        plan_quiz_btn.click(run_learning_plan_from_quiz, [quiz_name, quiz_state, lang_select], plan_quiz_output)
        plan_btn.click(run_learning_plan_interface, [plan_name, plan_goals, lang_select], plan_output)
        sum_btn.click(lambda t, l: run_summary_interface(t, l, retriever), [sum_topic, lang_select], sum_output)
        
        upload_btn_new.click(
            fn=upload_and_update_resource,
            inputs=[upload_files_new, selected_grandchild_state, knowledge_data_state],
            outputs=[upload_status_new, knowledge_data_state, resource_selector]
        )
        
    return demo

def launch_gradio() -> None:
    
    demo = build_interface()
    demo.queue()
    demo.launch()
